{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938af4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b88b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a8ec8",
   "metadata": {},
   "source": [
    "### 1. 솔루션 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c0bf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mediapipe.python.solutions.face_mesh' from 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\GMIC_env_py36\\\\lib\\\\site-packages\\\\mediapipe\\\\python\\\\solutions\\\\face_mesh.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "242308a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\n",
    "# LEFT_EYEBROW = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYEBROW)))\n",
    "\n",
    "# RIGHT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))\n",
    "\n",
    "# LIPS_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))\n",
    "\n",
    "#TESLE = list(set(itertools.chain(*mp_face_mesh.FACEMESH_TESSELATION)))\n",
    "\n",
    "CONTOURS_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACE_CONNECTIONS)))\n",
    "\n",
    "#FACE_LINE  = list(set(itertools.chain(*mp_face_mesh.FACEMESH_FACE_OVAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f764e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pixel_coords(relative_coords):\n",
    "    return(tuple(round(coord*dimension) for coord, dimension in zip(relative_coords, SCREEN_DIMENSIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2fa9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point(face_landmarks, location, idx, axis):\n",
    "    coor = face_landmarks.landmark[location[idx]]\n",
    "    pix = to_pixel_coords((coor.x, coor.y))\n",
    "    if axis=='x':\n",
    "        point = pix[0]\n",
    "    elif axis=='y':\n",
    "        point = pix[1]\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9b62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37b641a3",
   "metadata": {},
   "source": [
    "#### *좌표 순서 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db8c140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 이미지에 대해 좌표 순서 표시\n",
    "path = 'C:'\n",
    "image = cv2.imread(path + 'blue.png', cv2.IMREAD_UNCHANGED)\n",
    "image_input = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "height, width, _ = image.shape\n",
    "SCREEN_DIMENSIONS = (width, height)\n",
    "results = face_mesh.process(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "for face_landmarks in results.multi_face_landmarks: \n",
    "    for i, face_line_index in enumerate(CONTOURS_INDEXES):\n",
    "        coordi = face_landmarks.landmark[face_line_index]\n",
    "        coord = (coordi.x, coordi.y)\n",
    "        #SCREEN_DIMENSIONS = (image_cols, image_rows)\n",
    "        SCREEN_DIMENSIONS = (width, height)\n",
    "        \n",
    "        pixel = to_pixel_coords(coord)\n",
    "        cv2.putText(image_input, str(i), pixel, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "    cv2.imwrite(path + 'blue_test.png', image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181b83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ef2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b0541b",
   "metadata": {},
   "source": [
    "### Face detection & Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36dfb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:'\n",
    "images = os.listdir(path)\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "                                                                                                                          #image = cv2.imread(path + image_name)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        \n",
    "        startX = int(get_point(face_landmarks, CONTOURS_INDEXES, 65, axis='x')-(0.05*width))\n",
    "        startY = int(get_point(face_landmarks, CONTOURS_INDEXES, 2, axis='y')-(0.09*height))\n",
    "        endX = int(get_point(face_landmarks, CONTOURS_INDEXES, 126, axis='x')+(0.05*width))\n",
    "        endY = int(get_point(face_landmarks, CONTOURS_INDEXES, 47, axis='y')+(0.05*height))\n",
    "        \n",
    "        if endY > height:\n",
    "            endY = height\n",
    "            \n",
    "        if (startY < 0):\n",
    "            startY = 0\n",
    "            \n",
    "        if endX > width:\n",
    "            endX = width\n",
    "            \n",
    "        if (startX < 0):\n",
    "            startX = 0\n",
    "        \n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 0), 3)\n",
    "        face_img = image[startY:endY, startX:endX].copy()\n",
    "        \n",
    "        #cv2.imwrite('C:/Users/dbssk6904/PycharmProjects/DEMODEX/typical_TL/1. typical/preprocessed_data/1. face_detect/' + image_name, image)\n",
    "        cv2.imwrite('C:' + image_name, face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5945d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1694f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd0eca5",
   "metadata": {},
   "source": [
    "### 2. 비식별화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5db3cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "lip_order = [0,70,71,72,79,105,92,123,89,5,27,62,30,43,17,63,10,9,8]\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)   # image 열고 저장할 때, 자꾸 돌아가는 사진 있는데 이거 방지하기 위해 cv2.IMREAD_UNCHANGED\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    print(image_name)\n",
    "    \n",
    "    lip_coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        \n",
    "        # right eye\n",
    "        left = get_point(face_landmarks, CONTOURS_INDEXES, 7, axis='x')\n",
    "        right = get_point(face_landmarks, CONTOURS_INDEXES, 39, axis='x')\n",
    "        top = get_point(face_landmarks, CONTOURS_INDEXES, 53, axis='y')\n",
    "        bottom = get_point(face_landmarks, CONTOURS_INDEXES, 42, axis='y')\n",
    "\n",
    "        center_x = left + int((right-left)/2)\n",
    "        center_y = top + int((bottom-top)/2)\n",
    "\n",
    "        img = cv2.ellipse(image, (int(center_x*0.95), center_y), \n",
    "                          (int((right-center_x)*1.3), int((bottom-center_y)*1.8)), 0, 0, 360, (0,0,0), -1)\n",
    "\n",
    "        # left eye\n",
    "        left = get_point(face_landmarks, CONTOURS_INDEXES, 101, axis='x')\n",
    "        right = get_point(face_landmarks, CONTOURS_INDEXES, 69, axis='x')\n",
    "        top = get_point(face_landmarks, CONTOURS_INDEXES, 114, axis='y')\n",
    "        bottom = get_point(face_landmarks, CONTOURS_INDEXES, 104, axis='y')\n",
    "\n",
    "        center_x = left + int((right-left)/2)\n",
    "        center_y = top + int((bottom-top)/2)  \n",
    "\n",
    "        img = cv2.ellipse(img, (int(center_x*1.02), center_y), \n",
    "                          (int((right-center_x)*1.3), int((bottom-center_y)*1.8)), 0, 0, 360, (0,0,0), -1)\n",
    "\n",
    "        # lip\n",
    "        for idx in lip_order:\n",
    "            coordi = face_landmarks.landmark[CONTOURS_INDEXES[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "\n",
    "            lip_coordinates.append(pix)\n",
    "\n",
    "    pts = np.array(lip_coordinates, np.int32)\n",
    "\n",
    "    img = cv2.fillPoly(image, [pts], (0,0,0), cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imwrite('C:' + image_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8e46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0886eb",
   "metadata": {},
   "source": [
    "### 3. 전체 패턴 이미지\n",
    "\n",
    "참고 : https://stackoverflow.com/questions/48301186/cropping-concave-polygon-from-image-using-opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbbb4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:'\n",
    "images = os.listdir(path)\n",
    "\n",
    "idx_order = [2, 36, 21, 33, 14, 6, 56, 37, 65, 31, 38, 16, 58, 40, \n",
    "         46, 45, 60, 44, 47, 106, 121, 107, 108, 102, 119, 78, 100, 93, 126, \n",
    "         99, 117, 68, 76, 95, 83, 98]\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    print(image_name)\n",
    "    \n",
    "    coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        for idx in idx_order:\n",
    "            coordi = face_landmarks.landmark[CONTOURS_INDEXES[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "\n",
    "            coordinates.append(pix)\n",
    "    \n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    \n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    img = cv2.bitwise_or(image, image, mask=mask)\n",
    "\n",
    "    cv2.imwrite('C:' + image_name, img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e5309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b98d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b791b61",
   "metadata": {},
   "source": [
    "### 4. Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84249625",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8cdcfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 코 부분 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = base_path + '2. crop/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, CONTOURS_INDEXES, 39, axis='x')\n",
    "        w2 = get_point(face_landmarks, CONTOURS_INDEXES, 101, axis='x')\n",
    "        h1 = get_point(face_landmarks, CONTOURS_INDEXES, 35, axis='y')\n",
    "        h1 = int(h1*0.95)\n",
    "        h2 = get_point(face_landmarks, CONTOURS_INDEXES, 100, axis='y') \n",
    "        \n",
    "        if h1<0:\n",
    "            h1=0\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1) / 2)\n",
    "\n",
    "        patch_1 = image[h1:h, w1:w2]\n",
    "        patch_2 = image[h:h2, w1:w2]\n",
    "\n",
    "        cv2.imwrite(base_path + 'patch1/' + image_name, patch_1)\n",
    "        cv2.imwrite(base_path + 'patch2/' + image_name, patch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "287ae55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 오른쪽 볼 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = base_path + '2. crop/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, CONTOURS_INDEXES, 7, axis='x')\n",
    "        w1 = int(w1*0.9)\n",
    "        \n",
    "        w2 = get_point(face_landmarks, CONTOURS_INDEXES, 39, axis='x')\n",
    "        \n",
    "        h1 = get_point(face_landmarks, CONTOURS_INDEXES, 42, axis='y')\n",
    "        h1 = int(h1*1.02)\n",
    "        \n",
    "        h2 = get_point(face_landmarks, CONTOURS_INDEXES, 9, axis='y')\n",
    "        h2 = int(h2*0.98)\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1)/2)\n",
    "\n",
    "        patch_3 = image[h1:h, w1:w2]\n",
    "        patch_4 = image[h:h2, w1:w2]\n",
    "        \n",
    "        cv2.imwrite(base_path + 'patch3/' + image_name, patch_3)\n",
    "        cv2.imwrite(base_path + 'patch4/' + image_name, patch_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25449f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왼쪽 볼 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = base_path + '2. crop/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, CONTOURS_INDEXES, 101, axis='x')\n",
    "        \n",
    "        w2 = get_point(face_landmarks, CONTOURS_INDEXES, 69, axis='x')\n",
    "        w2 = int(w2*1.05)\n",
    "        \n",
    "        h1 = get_point(face_landmarks, CONTOURS_INDEXES, 104, axis='y')\n",
    "        h1 = int(h1*1.02)\n",
    "        \n",
    "        h2 = get_point(face_landmarks, CONTOURS_INDEXES, 71, axis='y')\n",
    "        h2 = int(h2*0.98)\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1)/2)\n",
    "\n",
    "        patch_5 = image[h1:h, w1:w2]\n",
    "        patch_6 = image[h:h2, w1:w2]\n",
    "        \n",
    "        cv2.imwrite(base_path + 'patch5/' + image_name, patch_5)\n",
    "        cv2.imwrite(base_path + 'patch6/' + image_name, patch_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d63b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 턱 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = base_path + '2. crop/'\n",
    "images = os.listdir(path)\n",
    "\n",
    "idx_order = [40, 46, 45, 60, 44, 47, 106, 121, 107, 108, 102]\n",
    "lip_idx_order = [79, 124, 72, 71, 70, 0, 8, 9, 10, 63]\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        for idx in idx_order:\n",
    "            coordi = face_landmarks.landmark[CONTOURS_INDEXES[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "            coordinates.append(pix)\n",
    "            \n",
    "        for lip_idx in lip_idx_order:\n",
    "            lip_coordi = face_landmarks.landmark[CONTOURS_INDEXES[lip_idx]]\n",
    "            lip_coord = [lip_coordi.x, lip_coordi.y]\n",
    "            lip_pix = list(to_pixel_coords((lip_coordi.x, (lip_coordi.y)-0.03)))\n",
    "            coordinates.append(lip_pix)\n",
    "    \n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    \n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    img = cv2.bitwise_and(image, image, mask=mask)\n",
    "    patch_7 = img[coordinates[15][1]-10:height, coordinates[0][0]-10:coordinates[10][0]+10]\n",
    "\n",
    "    cv2.imwrite(base_path + 'patch7/' + image_name, patch_7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178e9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503fbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b114b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9907e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d809cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3032bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
