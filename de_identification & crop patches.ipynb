{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb01955",
   "metadata": {},
   "source": [
    "© 2022 Yun Na Lee <imyun0315@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf98da1",
   "metadata": {},
   "source": [
    "코드 사용 시, 출처 표기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938af4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b88b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31642044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be3a8ec8",
   "metadata": {},
   "source": [
    "### 1. 솔루션 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c0bf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mediapipe.python.solutions.face_mesh' from 'C:\\\\Users\\\\dbssk6904\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\mediapipe\\\\python\\\\solutions\\\\face_mesh.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242308a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\n",
    "LEFT_EYEBROW = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYEBROW)))\n",
    "\n",
    "RIGHT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))\n",
    "\n",
    "LIPS_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))\n",
    "\n",
    "TESLE = list(set(itertools.chain(*mp_face_mesh.FACEMESH_TESSELATION)))\n",
    "\n",
    "CONTOURS_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_CONTOURS)))\n",
    "\n",
    "FACE_LINE  = list(set(itertools.chain(*mp_face_mesh.FACEMESH_FACE_OVAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f764e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pixel_coords(relative_coords):\n",
    "    return(tuple(round(coord*dimension) for coord, dimension in zip(relative_coords, SCREEN_DIMENSIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2fa9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point(face_landmarks, location, idx, axis):\n",
    "    coor = face_landmarks.landmark[location[idx]]\n",
    "    pix = to_pixel_coords((coor.x, coor.y))\n",
    "    if axis=='x':\n",
    "        point = pix[0]\n",
    "    elif axis=='y':\n",
    "        point = pix[1]\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9b62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37b641a3",
   "metadata": {},
   "source": [
    "#### *좌표 순서 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a253d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에 좌표 표시\n",
    "\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "images = os.listdir(path)\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    for face_landmarks in results.multi_face_landmarks: \n",
    "        for i, face_line_index in enumerate(FACE_LINE):\n",
    "            coordi = face_landmarks.landmark[face_line_index]\n",
    "            coord = (coordi.x, coordi.y)\n",
    "            SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "            pixel = to_pixel_coords(coord)\n",
    "            cv2.putText(image, str(i), pixel, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imwrite(path + image_name[:-4] + '_coordinate.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181b83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ef2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b0541b",
   "metadata": {},
   "source": [
    "### Face detection & Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36dfb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "images = os.listdir(path)\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "                                                                                                                         \n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        \n",
    "        startX = int(get_point(face_landmarks, CONTOURS_INDEXES, 65, axis='x')-(0.05*width))\n",
    "        startY = int(get_point(face_landmarks, CONTOURS_INDEXES, 2, axis='y')-(0.09*height))\n",
    "        endX = int(get_point(face_landmarks, CONTOURS_INDEXES, 126, axis='x')+(0.05*width))\n",
    "        endY = int(get_point(face_landmarks, CONTOURS_INDEXES, 47, axis='y')+(0.05*height))\n",
    "        \n",
    "        if endY > height:\n",
    "            endY = height\n",
    "            \n",
    "        if (startY < 0):\n",
    "            startY = 0\n",
    "            \n",
    "        if endX > width:\n",
    "            endX = width\n",
    "            \n",
    "        if (startX < 0):\n",
    "            startX = 0\n",
    "        \n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 0), 3)\n",
    "        face_img = image[startY:endY, startX:endX].copy()\n",
    "        \n",
    "\n",
    "        cv2.imwrite(path + 'face detect/' + image_name, face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5945d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1694f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd0eca5",
   "metadata": {},
   "source": [
    "### 2. 비식별화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5db3cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "lip_order = [0,70,71,72,79,105,92,123,89,5,27,62,30,43,17,63,10,9,8]\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)   # image 열고 저장할 때, 자꾸 돌아가는 사진 있는데 이거 방지하기 위해 cv2.IMREAD_UNCHANGED\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    print(image_name)\n",
    "    \n",
    "    lip_coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        \n",
    "        # right eye\n",
    "        left = get_point(face_landmarks, CONTOURS_INDEXES, 7, axis='x')\n",
    "        right = get_point(face_landmarks, CONTOURS_INDEXES, 39, axis='x')\n",
    "        top = get_point(face_landmarks, CONTOURS_INDEXES, 53, axis='y')\n",
    "        bottom = get_point(face_landmarks, CONTOURS_INDEXES, 42, axis='y')\n",
    "\n",
    "        center_x = left + int((right-left)/2)\n",
    "        center_y = top + int((bottom-top)/2)\n",
    "\n",
    "        img = cv2.ellipse(image, (int(center_x*0.95), center_y), \n",
    "                          (int((right-center_x)*1.3), int((bottom-center_y)*1.8)), 0, 0, 360, (0,0,0), -1)\n",
    "\n",
    "        # left eye\n",
    "        left = get_point(face_landmarks, CONTOURS_INDEXES, 101, axis='x')\n",
    "        right = get_point(face_landmarks, CONTOURS_INDEXES, 69, axis='x')\n",
    "        top = get_point(face_landmarks, CONTOURS_INDEXES, 114, axis='y')\n",
    "        bottom = get_point(face_landmarks, CONTOURS_INDEXES, 104, axis='y')\n",
    "\n",
    "        center_x = left + int((right-left)/2)\n",
    "        center_y = top + int((bottom-top)/2)  \n",
    "\n",
    "        img = cv2.ellipse(img, (int(center_x*1.02), center_y), \n",
    "                          (int((right-center_x)*1.3), int((bottom-center_y)*1.8)), 0, 0, 360, (0,0,0), -1)\n",
    "\n",
    "        # lip\n",
    "        for idx in lip_order:\n",
    "            coordi = face_landmarks.landmark[CONTOURS_INDEXES[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "\n",
    "            lip_coordinates.append(pix)\n",
    "\n",
    "    pts = np.array(lip_coordinates, np.int32)\n",
    "\n",
    "    img = cv2.fillPoly(image, [pts], (0,0,0), cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imwrite(path + 'de_iden/' + image_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8e46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997ad08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0886eb",
   "metadata": {},
   "source": [
    "### 3. background 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbbb4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = \"C:/Users/\"\n",
    "images = os.listdir(path)\n",
    "\n",
    "idx_order = [3, 23, 14, 22, 11, 34, 1, 25, 21, 19, 27, 12, 4, 30, \n",
    "         31, 33, 5, 32, 10, 6, 16, 7, 8, 2, 15, 18, 0, 24, 28, \n",
    "         35, 13, 9, 17, 26, 20, 29]\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name, cv2.IMREAD_UNCHANGED)\n",
    "    print(image_name)\n",
    "    \n",
    "    coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        for idx in idx_order:\n",
    "            coordi = face_landmarks.landmark[FACE_LINE[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "\n",
    "            coordinates.append(pix)\n",
    "    \n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    \n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    img = cv2.bitwise_or(image, image, mask=mask)\n",
    "\n",
    "    cv2.imwrite(path + \"whole/\" + image_name, img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e5309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b98d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b791b61",
   "metadata": {},
   "source": [
    "### 4. Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8cdcfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 코 부분 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, RIGHT_EYE_INDEXES, 4, axis='x')\n",
    "        w2 = get_point(face_landmarks, LEFT_EYE_INDEXES, 7, axis='x')\n",
    "        h1 = get_point(face_landmarks, LEFT_EYEBROW, 5, axis='y')\n",
    "        h1 = int(h1*0.95)\n",
    "        h2 = get_point(face_landmarks, TESLE, 370, axis='y') \n",
    "        \n",
    "        if h1<0:\n",
    "            h1=0\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1) / 2)\n",
    "\n",
    "        patch_1 = image[h1:h, w1:w2]\n",
    "        patch_2 = image[h:h2, w1:w2]\n",
    "\n",
    "        cv2.imwrite(path + '1. patches/' + image_name, patch_1)\n",
    "        cv2.imwrite(path + '2. patches/' + image_name, patch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "287ae55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 오른쪽 볼 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, RIGHT_EYE_INDEXES, 1, axis='x')\n",
    "        w1 = int(w1*0.9)\n",
    "        \n",
    "        w2 = get_point(face_landmarks, RIGHT_EYE_INDEXES, 4, axis='x')\n",
    "        \n",
    "        h1 = get_point(face_landmarks, RIGHT_EYE_INDEXES, 8, axis='y')\n",
    "        h1 = int(h1*1.02)\n",
    "        \n",
    "        h2 = get_point(face_landmarks, LIPS_INDEXES, 15, axis='y')\n",
    "        h2 = int(h2*0.98)\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1)/2)\n",
    "\n",
    "        patch_3 = image[h1:h, w1:w2]\n",
    "        patch_4 = image[h:h2, w1:w2]\n",
    "        \n",
    "        cv2.imwrite(path + '3. patches/' + image_name, patch_3)\n",
    "        cv2.imwrite(path + '4. patches/' + image_name, patch_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25449f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왼쪽 볼 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "crop_images = os.listdir(path)\n",
    "\n",
    "for image_name in crop_images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name)\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        w1 = get_point(face_landmarks, LEFT_EYE_INDEXES, 7, axis='x')\n",
    "        \n",
    "        w2 = get_point(face_landmarks, LEFT_EYE_INDEXES, 6, axis='x')\n",
    "        w2 = int(w2*1.05)\n",
    "        \n",
    "        h1 = get_point(face_landmarks, LEFT_EYE_INDEXES, 11, axis='y')\n",
    "        h1 = int(h1*1.02)\n",
    "        \n",
    "        h2 = get_point(face_landmarks, LIPS_INDEXES, 3, axis='y')\n",
    "        h2 = int(h2*0.98)\n",
    "\n",
    "        #print(h1, h2, w1, w2)\n",
    "        h = h1 + int((h2-h1)/2)\n",
    "\n",
    "        patch_5 = image[h1:h, w1:w2]\n",
    "        patch_6 = image[h:h2, w1:w2]\n",
    "        \n",
    "        cv2.imwrite(path + '5. patches/' + image_name, patch_5)\n",
    "        cv2.imwrite(path + '6. patches/' + image_name, patch_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d63b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 턱 패치\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "path = 'C:/Users/'\n",
    "images = os.listdir(path)\n",
    "\n",
    "idx_order = [30, 31, 33, 5, 32, 10, 6, 16, 7, 8, 2]\n",
    "lip_idx_order = [26, 22, 15, 14, 13, 1, 2, 3, 10, 12]\n",
    "\n",
    "for image_name in images:\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    height, width, _ = image.shape          \n",
    "    SCREEN_DIMENSIONS = (width, height)\n",
    "\n",
    "    results = face_mesh.process(cv2.cvtColor(image , cv2.COLOR_BGR2RGB))\n",
    "    image = cv2.imread(path + image_name)\n",
    "    \n",
    "    coordinates = []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        for idx in idx_order:\n",
    "            coordi = face_landmarks.landmark[FACE_LINE[idx]]\n",
    "            coord = [coordi.x, coordi.y]\n",
    "            pix = list(to_pixel_coords((coordi.x, coordi.y)))\n",
    "            coordinates.append(pix)\n",
    "            \n",
    "        for lip_idx in lip_idx_order:\n",
    "            lip_coordi = face_landmarks.landmark[LIPS_INDEXES[lip_idx]]\n",
    "            lip_coord = [lip_coordi.x, lip_coordi.y]\n",
    "            lip_pix = list(to_pixel_coords((lip_coordi.x, (lip_coordi.y)-0.03)))\n",
    "            coordinates.append(lip_pix)\n",
    "    \n",
    "    pts = np.array(coordinates, np.int32)\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    \n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    img = cv2.bitwise_and(image, image, mask=mask)\n",
    "    patch_7 = img[coordinates[15][1]-10:height, coordinates[10][0]-10:coordinates[0][0]+10]\n",
    "\n",
    "    cv2.imwrite(path + '7. patches/' + image_name, patch_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178e9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6771fed",
   "metadata": {},
   "source": [
    "### 5. Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18efddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize(load_path, image_name, size, save_path):\n",
    "    \n",
    "    base_mask = np.zeros((size[1], size[0], 3), np.uint8)\n",
    "    image = cv2.imread(load_path + image_name, cv2.IMREAD_COLOR)\n",
    "    h, w = image.shape[:2]\n",
    "        \n",
    "    ash = size[1]/h\n",
    "    asw = size[0]/w\n",
    "\n",
    "    if asw < ash:\n",
    "        sizeas = (int(w*asw), int(h*asw))\n",
    "    else:\n",
    "        sizeas = (int(w*ash), int(h*ash))\n",
    "\n",
    "    resize_img = cv2.resize(image, dsize=sizeas)\n",
    "    base_mask[int(size[1]/2 - sizeas[1]/2):int(size[1]/2 + sizeas[1]/2),\n",
    "              int(size[0]/2 - sizeas[0]/2):int(size[0]/2 + sizeas[0]/2), :] = resize_img\n",
    "\n",
    "    cv2.imwrite(save_path + image_name, base_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725771f",
   "metadata": {},
   "source": [
    "##### - whole region images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f05dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = 'C:/Users/'\n",
    "save_path = 'C:/Users/'\n",
    "\n",
    "size = (513, 513)    \n",
    "\n",
    "images = os.listdir(load_path)\n",
    "\n",
    "for image_name in images:\n",
    "    img_resize(load_path, image_name, size, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1379acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f0707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503fbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b114b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9907e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d809cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3032bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843c8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seve_39",
   "language": "python",
   "name": "severance_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
